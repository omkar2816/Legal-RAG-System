#!/usr/bin/env python3
"""
Test script to verify complete response improvements
"""
import os
import sys
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Add the project root to the path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_token_limit_increase():
    """Test that token limit has been further increased"""
    print("ğŸ”§ Testing Token Limit Increase")
    print("=" * 50)
    
    try:
        from config.settings import settings
        
        print(f"Current GROQ_MAX_TOKENS: {settings.GROQ_MAX_TOKENS}")
        
        if settings.GROQ_MAX_TOKENS >= 8000:
            print("âœ… Token limit has been increased to 8000+ tokens")
            return True
        else:
            print(f"âŒ Token limit is still low: {settings.GROQ_MAX_TOKENS}")
            return False
            
    except Exception as e:
        print(f"âŒ Error: {str(e)}")
        return False

def test_improved_prompts():
    """Test improved prompt templates"""
    print("\nğŸ“ Testing Improved Prompts")
    print("=" * 50)
    
    try:
        from config.settings import settings
        
        print("System Prompt:")
        print(settings.SYSTEM_PROMPT)
        print("\n" + "-" * 50)
        print("Query Prompt Template:")
        print(settings.QUERY_PROMPT_TEMPLATE)
        
        # Check if prompts include completion instructions
        if "complete" in settings.SYSTEM_PROMPT.lower() and "truncate" in settings.SYSTEM_PROMPT.lower():
            print("\nâœ… System prompt includes completion instructions")
        else:
            print("\nâŒ System prompt missing completion instructions")
            return False
            
        if "complete" in settings.QUERY_PROMPT_TEMPLATE.lower() and "stop mid-sentence" in settings.QUERY_PROMPT_TEMPLATE.lower():
            print("âœ… Query prompt includes completion instructions")
        else:
            print("âŒ Query prompt missing completion instructions")
            return False
            
        return True
        
    except Exception as e:
        print(f"âŒ Error: {str(e)}")
        return False

def test_multiple_questions_enhancement():
    """Test multiple questions enhancement"""
    print("\nğŸ” Testing Multiple Questions Enhancement")
    print("=" * 50)
    
    try:
        from utils.query_enhancer import detect_multiple_questions
        
        # Test query with multiple questions
        test_query = "What is maximum waiting period for treatment of joint replacement?, What does the policy define as a Pre-Existing Disease?, What is the waiting period for cataract treatment under this policy?, What is the maximum co-payment percentage applicable under this policy? When does it apply?"
        
        print(f"Original Query: {test_query}")
        
        # Detect multiple questions
        questions = detect_multiple_questions(test_query)
        print(f"\nDetected {len(questions)} questions:")
        for i, q in enumerate(questions, 1):
            print(f"  {i}. {q}")
        
        if len(questions) > 1:
            print("âœ… Multiple questions detection working")
            return True
        else:
            print("âŒ Multiple questions detection failed")
            return False
        
    except Exception as e:
        print(f"âŒ Error: {str(e)}")
        return False

def test_llm_client_improvements():
    """Test LLM client improvements"""
    print("\nğŸ¤– Testing LLM Client Improvements")
    print("=" * 50)
    
    try:
        from llm_service.llm_client import llm_client
        
        print(f"Model: {llm_client.model}")
        print(f"Max Tokens: {llm_client.max_tokens}")
        print(f"Temperature: {llm_client.temperature}")
        
        if llm_client.max_tokens >= 8000:
            print("âœ… LLM client configured with increased token limit")
            
            # Test the new methods exist
            if hasattr(llm_client, '_enhance_multiple_questions_prompt'):
                print("âœ… Multiple questions enhancement method exists")
            else:
                print("âŒ Multiple questions enhancement method missing")
                return False
                
            if hasattr(llm_client, '_validate_response_completeness'):
                print("âœ… Response validation method exists")
            else:
                print("âŒ Response validation method missing")
                return False
                
            return True
        else:
            print(f"âŒ LLM client still has low token limit: {llm_client.max_tokens}")
            return False
            
    except Exception as e:
        print(f"âŒ Error: {str(e)}")
        return False

def test_complete_response_generation():
    """Test complete response generation"""
    print("\nğŸ§ª Testing Complete Response Generation")
    print("=" * 50)
    
    # Check if API keys are available
    if not os.getenv("GROQ_API_KEY"):
        print("âš ï¸  GROQ_API_KEY not set, skipping response generation test")
        return True
    
    try:
        from llm_service.llm_client import llm_client
        
        # Test with a multiple questions prompt
        test_prompt = "Please answer these questions: 1. What is the waiting period? 2. What are the exclusions? 3. What is the coverage amount? 4. When does it apply?"
        
        print("Testing complete response generation...")
        
        # Create mock context chunks
        mock_chunks = [{
            'metadata': {
                'doc_title': 'Test Policy',
                'section_title': 'Test Section'
            },
            'text': 'This is a test policy document with information about waiting periods, exclusions, coverage amounts, and application conditions.'
        }]
        
        response = llm_client.generate_legal_response(test_prompt, mock_chunks)
        
        print(f"Response length: {len(response)} characters")
        print(f"Response preview: {response[:300]}...")
        
        # Check if response seems complete
        if len(response) > 200 and not response.endswith('.'):
            print("âœ… Response generation working with increased token limit")
            return True
        else:
            print("âŒ Response seems too short or incomplete")
            return False
            
    except Exception as e:
        print(f"âŒ Error in response generation: {str(e)}")
        return False

def main():
    """Main test function"""
    print("ğŸš€ Testing Complete Response Improvements")
    print("=" * 60)
    
    # Test 1: Token limit increase
    token_success = test_token_limit_increase()
    
    # Test 2: Improved prompts
    prompt_success = test_improved_prompts()
    
    # Test 3: Multiple questions enhancement
    questions_success = test_multiple_questions_enhancement()
    
    # Test 4: LLM client improvements
    client_success = test_llm_client_improvements()
    
    # Test 5: Complete response generation
    response_success = test_complete_response_generation()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š Test Results Summary")
    print("=" * 60)
    
    print(f"Token Limit Increase: {'âœ… PASS' if token_success else 'âŒ FAIL'}")
    print(f"Improved Prompts: {'âœ… PASS' if prompt_success else 'âŒ FAIL'}")
    print(f"Multiple Questions Enhancement: {'âœ… PASS' if questions_success else 'âŒ FAIL'}")
    print(f"LLM Client Improvements: {'âœ… PASS' if client_success else 'âŒ FAIL'}")
    print(f"Complete Response Generation: {'âœ… PASS' if response_success else 'âŒ FAIL'}")
    
    if all([token_success, prompt_success, questions_success, client_success, response_success]):
        print("\nğŸ‰ All tests passed! Complete response improvements are working.")
        print("Your system should now provide complete answers to all questions without truncation.")
    else:
        print("\nâš ï¸  Some tests failed. Please check the error messages above.")
    
    print("\nğŸ“‹ Expected Improvements:")
    print("â€¢ Token limit increased from 4000 to 8000 tokens")
    print("â€¢ Enhanced prompts with completion instructions")
    print("â€¢ Better multiple questions handling")
    print("â€¢ Response validation and completeness checking")
    print("â€¢ No more truncated responses")
    
    print("\nğŸ§ª Test your improved system:")
    print("1. Update your .env file: GROQ_MAX_TOKENS=8000")
    print("2. Restart your server: uvicorn api.main:app --reload")
    print("3. Try the same multi-question query that was cut off before")
    print("4. You should now get complete answers to ALL questions!")

if __name__ == "__main__":
    main() 