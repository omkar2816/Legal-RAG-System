"""
Embedding client for generating vector representations of text
"""
from openai import OpenAI
import numpy as np
from typing import List, Union
from config.settings import settings
import logging
import os

logger = logging.getLogger(__name__)

class EmbeddingClient:
    """Client for generating embeddings using OpenAI"""
    
    def __init__(self, model: str = None):
        self.model = model or settings.EMBEDDING_MODEL
        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
    
    def get_embeddings(self, text_list: List[str], batch_size: int = None) -> List[List[float]]:
        """
        Generate embeddings for a list of texts
        
        Args:
            text_list: List of text strings to embed
            batch_size: Batch size for processing (defaults to settings)
        
        Returns:
            List of embedding vectors
        """
        if batch_size is None:
            batch_size = settings.EMBEDDING_BATCH_SIZE
        
        all_embeddings = []
        
        # Process in batches
        for i in range(0, len(text_list), batch_size):
            batch = text_list[i:i + batch_size]
            
            try:
                response = self.client.embeddings.create(
                    input=batch,
                    model=self.model
                )
                
                batch_embeddings = [d.embedding for d in response.data]
                all_embeddings.extend(batch_embeddings)
                
                logger.info(f"Generated embeddings for batch {i//batch_size + 1}")
                
            except Exception as e:
                logger.error(f"Error generating embeddings for batch {i//batch_size + 1}: {e}")
                
                # Try to use mock embeddings if OpenAI API fails
                try:
                    from embeddings.mock_embed_client import mock_embedding_client
                    logger.info("Falling back to mock embeddings")
                    mock_embeddings = mock_embedding_client.get_embeddings(batch)
                    all_embeddings.extend(mock_embeddings)
                except Exception as mock_error:
                    logger.error(f"Mock embedding also failed: {mock_error}")
                    # Return zero vectors as last resort
                    zero_embedding = [0.0] * 1024  # Match Pinecone index dimension
                    all_embeddings.extend([zero_embedding] * len(batch))
        
        return all_embeddings
    
    def get_single_embedding(self, text: str) -> List[float]:
        """
        Generate embedding for a single text
        
        Args:
            text: Text string to embed
        
        Returns:
            Embedding vector
        """
        embeddings = self.get_embeddings([text])
        return embeddings[0] if embeddings else []
    
    def get_embedding_dimension(self) -> int:
        """
        Get the dimension of embeddings generated by this model
        
        Returns:
            Embedding dimension
        """
        # OpenAI embedding model dimensions
        if "text-embedding-3-small" in self.model:
            return 1024
        elif "text-embedding-3-large" in self.model:
            return 3072
        elif "text-embedding-ada-002" in self.model:
            return 1536
        else:
            # Default to 1024 for compatibility with existing index
            return 1024

# Global embedding client instance
embedding_client = EmbeddingClient()

def get_embeddings(text_list: List[str], model: str = None) -> List[List[float]]:
    """
    Convenience function to get embeddings
    
    Args:
        text_list: List of text strings
        model: Model name (optional)
    
    Returns:
        List of embedding vectors
    """
    client = EmbeddingClient(model) if model else embedding_client
    return client.get_embeddings(text_list)